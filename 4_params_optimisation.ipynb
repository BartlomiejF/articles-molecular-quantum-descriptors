{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import typing\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import Descriptors\n",
    "from typing import Union, List, Tuple\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Descriptors3D\n",
    "from rdkit.Chem import GraphDescriptors\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern_count(molecule: Chem.Mol, pattern: Chem.Mol) -> int:\n",
    "    result = molecule.GetSubstructMatches(pattern)\n",
    "    return len(result)\n",
    "\n",
    "def drawSmils(smils: str):\n",
    "    smilsChromoChem = Chem.MolFromSmiles(smils)\n",
    "    drawing = Draw.MolToMPL(smilsChromoChem, size=(450,450))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_database = pd.read_csv(\"qm9.csv\")\n",
    "qm9_database[\"RDKit_Mol_Class\"] = qm9_database[\"smiles\"].apply(Chem.MolFromSmiles)\n",
    "only_solids = pd.read_json(\"only_solids_features.json\").reset_index(drop=True)\n",
    "only_solids_conf = pd.read_json(\"only_solids_conf_features.json\").reset_index(drop=True)\n",
    "only_solids[\"RDKit_Mol_Class\"] = only_solids[\"Chromophore\"].apply(Chem.MolFromSmiles)\n",
    "only_solids_conf[\"RDKit_Mol_Class\"] = only_solids_conf[\"Chromophore\"].apply(Chem.MolFromSmiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_4_cols = [\"Chromophore\", 'qm9_pattern_indexes', 'RDKit_Mol_Class', \"Emission max (nm)\"]\n",
    "only_solids = pd.concat([only_solids[first_4_cols], only_solids.drop(columns=first_4_cols)], axis=1)\n",
    "only_solids_conf = pd.concat([only_solids_conf[first_4_cols], only_solids_conf.drop(columns=first_4_cols)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is important cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### toggle between dataset 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only_solids = only_solids_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_names = [ x[0] for x in Descriptors._descList ]\n",
    "len(descriptors_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(only_solids[descriptors_names])\n",
    "only_solids = pd.concat([only_solids[only_solids.columns.drop(descriptors_names)].reset_index(drop=True), pd.DataFrame(scaler.transform(only_solids[descriptors_names]), columns=descriptors_names)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_solids.drop(only_solids.std()[only_solids.std()==0].index, axis=1, inplace=True)\n",
    "only_solids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans_cols = only_solids.columns[only_solids.isna().any()]\n",
    "nans_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_solids.dropna(subset=nans_cols, axis=0, inplace=True)\n",
    "only_solids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "universal_features = list(only_solids.columns)[4:]\n",
    "universal_features_conf = list(only_solids_conf.columns)[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_data_conf_x = only_solids[universal_features]\n",
    "model1_data_conf_y = only_solids[\"Emission max (nm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm9_database[\"chemical_potential\"] = (qm9_database[\"homo\"]+qm9_database[\"lumo\"])/2\n",
    "qm9_database[\"electrophilicity\"] = qm9_database[\"chemical_potential\"]**2/(2*qm9_database[\"gap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quantum_features = list(qm9_database.columns.drop([\"RDKit_Mol_Class\", \"mol_id\", \"smiles\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"n_features\", \"max_depth\", \"n_est\", \"mae\"]\n",
    "n_estimators_range = list(range(100, 1050, 50))\n",
    "min_samples_range = list(range(1, 40))\n",
    "features_range = np.linspace(0.05, 1, 20)\n",
    "depth_range = list(range(3, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model1 = pd.DataFrame(columns=cols)\n",
    "scores_model2 = scores_model1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = model1_data_conf_x\n",
    "data_y = model1_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "#     \"neg_mean_squared_error\",\n",
    "#     \"r2\",\n",
    "#     \"max_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "]\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "for depth in depth_range:\n",
    "    for features in features_range:\n",
    "        for est in n_estimators_range:\n",
    "            scores_dict[\"n_features\"] = features\n",
    "            scores_dict[\"max_depth\"] = depth\n",
    "            scores_dict[\"n_est\"] = est\n",
    "            gbr = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                            max_depth=depth,\n",
    "                                            max_features=features,\n",
    "                                            n_estimators=est,\n",
    "                                           random_state=1)\n",
    "            for scor_type in scores:\n",
    "                scores_dict[\"mae\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "                print(f\"GBR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\")\n",
    "            scores_model1 = scores_model1.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model1.to_json(\"gbr_scores1_model1.json\")\n",
    "scores_model1 = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = model1_data_conf_x\n",
    "data_y = model1_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "    \"neg_mean_squared_error\",\n",
    "    \"r2\",\n",
    "    \"max_error\",\n",
    "#     \"neg_mean_absolute_error\",\n",
    "]\n",
    "cols = [\"n_features\", \"max_depth\", \"n_est\"] + scores\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "depth = 4\n",
    "for features in features_range:\n",
    "    for est in n_estimators_range:\n",
    "        scores_dict[\"n_features\"] = features\n",
    "        scores_dict[\"max_depth\"] = depth\n",
    "        scores_dict[\"n_est\"] = est\n",
    "        gbr = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                        max_depth=5,\n",
    "                                        max_features=features,\n",
    "                                        n_estimators=est,\n",
    "                                       random_state=1)\n",
    "        for scor_type in scores:\n",
    "            scores_dict[f\"{scor_type}\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "            print(f\"GBR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\")\n",
    "        scores_model1 = scores_model1.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model1.to_json(\"gbr_scores2_model1.json\")\n",
    "scores_model1 = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(row, database: pd.DataFrame, features: Union[List[str], str]) -> None:\n",
    "    for index in row[\"qm9_pattern_indexes\"]:\n",
    "        count = find_pattern_count(row[\"RDKit_Mol_Class\"], database[\"RDKit_Mol_Class\"][index])\n",
    "        for feature in features:\n",
    "            value = count*database[feature][index]\n",
    "            row[feature] += value\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = all_quantum_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_solids[features] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_solids = only_solids.apply(get_features, database=qm9_database, features=features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_data_conf_x = only_solids[universal_features+features]\n",
    "model2_data_conf_y = only_solids[\"Emission max (nm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = model2_data_conf_x\n",
    "data_y = model2_data_conf_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = model2_data_conf_x\n",
    "data_y = model2_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "#     \"neg_mean_squared_error\",\n",
    "#     \"r2\",\n",
    "#     \"max_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "]\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "for depth in depth_range:\n",
    "    for features in features_range:\n",
    "        for est in n_estimators_range:\n",
    "            scores_dict[\"n_features\"] = features\n",
    "            scores_dict[\"max_depth\"] = depth\n",
    "            scores_dict[\"n_est\"] = est\n",
    "            gbr = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                            max_depth=depth,\n",
    "                                            max_features=features,\n",
    "                                            n_estimators=est,\n",
    "                                           random_state=1)\n",
    "            for scor_type in scores:\n",
    "                scores_dict[\"mae\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "                print(f\"GBR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\")\n",
    "            scores_model2 = scores_model2.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = model2_data_conf_x\n",
    "data_y = model2_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "    \"neg_mean_squared_error\",\n",
    "    \"r2\",\n",
    "    \"max_error\",\n",
    "#     \"neg_mean_absolute_error\",\n",
    "]\n",
    "cols = [\"n_features\", \"max_depth\", \"n_est\"] + scores\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "depth = 3\n",
    "for features in features_range:\n",
    "    for est in n_estimators_range:\n",
    "        scores_dict[\"n_features\"] = features\n",
    "        scores_dict[\"max_depth\"] = depth\n",
    "        scores_dict[\"n_est\"] = est\n",
    "        gbr = GradientBoostingRegressor(learning_rate=0.05,\n",
    "                                        max_depth=depth,\n",
    "                                        max_features=features,\n",
    "                                        n_estimators=est,\n",
    "                                       random_state=1)\n",
    "        for scor_type in scores:\n",
    "            scores_dict[f\"{scor_type}\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "            print(f\"GBR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\")\n",
    "        scores_model2 = scores_model2.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model2.to_json(\"gbr_scores2_model2.json\")\n",
    "scores_model2 = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = model1_data_conf_x\n",
    "data_y = model1_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "#     \"neg_mean_squared_error\",\n",
    "#     \"r2\",\n",
    "#     \"max_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "]\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "for depth in depth_range:\n",
    "    for features in features_range:\n",
    "        for est in n_estimators_range:\n",
    "            scores_dict[\"n_features\"] = features\n",
    "            scores_dict[\"max_depth\"] = depth\n",
    "            scores_dict[\"n_est\"] = est\n",
    "            gbr = RandomForestRegressor(max_depth=depth,\n",
    "                                            max_features=features,\n",
    "                                            n_estimators=est,\n",
    "                                           random_state=1)\n",
    "            for scor_type in scores:\n",
    "                scores_dict[\"mae\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "                print(f\"RFR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\")\n",
    "            scores_model1 = scores_model1.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model1.to_json(\"rfr_scores1_model1.json\")\n",
    "scores_model1 = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = model2_data_conf_x\n",
    "data_y = model2_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "#     \"neg_mean_squared_error\",\n",
    "#     \"r2\",\n",
    "#     \"max_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "]\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "for depth in depth_range:\n",
    "    for features in features_range:\n",
    "        for est in n_estimators_range:\n",
    "            scores_dict[\"n_features\"] = features\n",
    "            scores_dict[\"max_depth\"] = depth\n",
    "            scores_dict[\"n_est\"] = est\n",
    "            gbr = RandomForestRegressor(max_depth=depth,\n",
    "                                            max_features=features,\n",
    "                                            n_estimators=est,\n",
    "                                           random_state=1)\n",
    "            for scor_type in scores:\n",
    "                scores_dict[\"mae\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "                print(f\"RFR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\"))\n",
    "            scores_model2 = scores_model2.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model2.to_json(\"rfr_scores1_model2.json\")\n",
    "scores_model2 = scores_model1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_range = list(range(3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_x = model1_data_conf_x\n",
    "data_y = model1_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "    \"neg_mean_squared_error\",\n",
    "    \"r2\",\n",
    "    \"max_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "]\n",
    "est = 600\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "for depth in depth_range:\n",
    "    for features in features_range:\n",
    "        scores_dict[\"n_features\"] = features\n",
    "        scores_dict[\"max_depth\"] = depth\n",
    "        scores_dict[\"n_est\"] = 600\n",
    "        gbr = RandomForestRegressor(max_depth=depth,\n",
    "                                        max_features=features,\n",
    "                                        n_estimators=600,\n",
    "                                       random_state=1)\n",
    "        for scor_type in scores:\n",
    "            scores_dict[f\"{scor_type}\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "            print(f\"RFR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\")\n",
    "        scores_model1 = scores_model1.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model1.to_json(\"rfr_scores2_model1.json\")\n",
    "scores_model1 = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_x = model2_data_conf_x\n",
    "data_y = model2_data_conf_y\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "scores = [\n",
    "    \"neg_mean_squared_error\",\n",
    "    \"r2\",\n",
    "    \"max_error\",\n",
    "    \"neg_mean_absolute_error\",\n",
    "]\n",
    "est = 600\n",
    "scores_dict = {col: 0 for col in cols}\n",
    "for depth in depth_range:\n",
    "    for features in features_range:\n",
    "        scores_dict[\"n_features\"] = features\n",
    "        scores_dict[\"max_depth\"] = depth\n",
    "        scores_dict[\"n_est\"] = 600\n",
    "        gbr = RandomForestRegressor(max_depth=depth,\n",
    "                                        max_features=features,\n",
    "                                        n_estimators=600,\n",
    "                                       random_state=1)\n",
    "        for scor_type in scores:\n",
    "            scores_dict[f\"{scor_type}\"] = cross_val_score(gbr, data_x, data_y, cv=kf, scoring=scor_type).mean()\n",
    "            print(f\"RFR max_depth: {depth} max_features: {features} n_est: {est} {scor_type}: {scores_dict[f'{scor_type}']}\")\n",
    "        scores_model2 = scores_model2.append(pd.DataFrame(scores_dict, index=[0]), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model2.to_json(\"rfr_scores2_model2.json\")\n",
    "scores_model2 = pd.DataFrame(columns=cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
